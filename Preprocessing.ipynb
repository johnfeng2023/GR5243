{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform the following preprocessing steps: \n",
    "\n",
    "1. Drop unnecessary columns\n",
    "2. Convert Date Columns to datetime Format\n",
    "3. Hnadle Missing Values\n",
    "4. Remove Duplicate Rows\n",
    "5. Handle Outliers using Winsorization\n",
    "6. Scale Only Stock Market Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop unnecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Date</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>webTitle</th>\n",
       "      <th>webUrl</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4745.200195</td>\n",
       "      <td>4754.330078</td>\n",
       "      <td>4722.669922</td>\n",
       "      <td>4742.830078</td>\n",
       "      <td>3743050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>tv-and-radio/2024/jan/03/detroiters-sitcom-tim...</td>\n",
       "      <td>article</td>\n",
       "      <td>Television &amp; radio</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Before I Think You Should Leave, there was Det...</td>\n",
       "      <td>https://www.theguardian.com/tv-and-radio/2024/...</td>\n",
       "      <td>Before I Think You Should Leave, there was Det...</td>\n",
       "      <td>&lt;p&gt;Pinning down why Tim Robinson is funny is v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4745.200195</td>\n",
       "      <td>4754.330078</td>\n",
       "      <td>4722.669922</td>\n",
       "      <td>4742.830078</td>\n",
       "      <td>3743050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>environment/2024/jan/02/climate-crisis-2023-wa...</td>\n",
       "      <td>article</td>\n",
       "      <td>Environment</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Climate crisis: 2023 was UK’s second-hottest y...</td>\n",
       "      <td>https://www.theguardian.com/environment/2024/j...</td>\n",
       "      <td>Climate crisis: 2023 was UK’s second-hottest y...</td>\n",
       "      <td>&lt;p&gt;The UK had its second-hottest year on recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4745.200195</td>\n",
       "      <td>4754.330078</td>\n",
       "      <td>4722.669922</td>\n",
       "      <td>4742.830078</td>\n",
       "      <td>3743050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>business/2024/jan/02/uk-grocery-inflation-food...</td>\n",
       "      <td>article</td>\n",
       "      <td>Business</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>UK shop inflation sticks at 4.3% despite lower...</td>\n",
       "      <td>https://www.theguardian.com/business/2024/jan/...</td>\n",
       "      <td>UK shop inflation sticks at 4.3% despite lower...</td>\n",
       "      <td>&lt;p&gt;Shop prices continued to rise at 4.3% in De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4745.200195</td>\n",
       "      <td>4754.330078</td>\n",
       "      <td>4722.669922</td>\n",
       "      <td>4742.830078</td>\n",
       "      <td>3743050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>stage/2024/jan/02/oliver-emanuel-obituary</td>\n",
       "      <td>article</td>\n",
       "      <td>Stage</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Oliver Emanuel obituary</td>\n",
       "      <td>https://www.theguardian.com/stage/2024/jan/02/...</td>\n",
       "      <td>Oliver Emanuel obituary</td>\n",
       "      <td>&lt;p&gt;Oliver Emanuel, who has died aged 43 from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4745.200195</td>\n",
       "      <td>4754.330078</td>\n",
       "      <td>4722.669922</td>\n",
       "      <td>4742.830078</td>\n",
       "      <td>3743050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>business/live/2024/jan/02/aldi-lidl-enjoy-reco...</td>\n",
       "      <td>liveblog</td>\n",
       "      <td>Business</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Tesla overtaken by China’s BYD as world’s top-...</td>\n",
       "      <td>https://www.theguardian.com/business/live/2024...</td>\n",
       "      <td>Tesla overtaken by China’s BYD as world’s top-...</td>\n",
       "      <td>&lt;div id=\"block-6594260e8f083d1e9a9aea1a\" class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open         High          Low        Close      Volume  Dividends  \\\n",
       "0  4745.200195  4754.330078  4722.669922  4742.830078  3743050000        0.0   \n",
       "1  4745.200195  4754.330078  4722.669922  4742.830078  3743050000        0.0   \n",
       "2  4745.200195  4754.330078  4722.669922  4742.830078  3743050000        0.0   \n",
       "3  4745.200195  4754.330078  4722.669922  4742.830078  3743050000        0.0   \n",
       "4  4745.200195  4754.330078  4722.669922  4742.830078  3743050000        0.0   \n",
       "\n",
       "   Stock Splits        Date  \\\n",
       "0           0.0  2024-01-02   \n",
       "1           0.0  2024-01-02   \n",
       "2           0.0  2024-01-02   \n",
       "3           0.0  2024-01-02   \n",
       "4           0.0  2024-01-02   \n",
       "\n",
       "                                                  id      type  \\\n",
       "0  tv-and-radio/2024/jan/03/detroiters-sitcom-tim...   article   \n",
       "1  environment/2024/jan/02/climate-crisis-2023-wa...   article   \n",
       "2  business/2024/jan/02/uk-grocery-inflation-food...   article   \n",
       "3          stage/2024/jan/02/oliver-emanuel-obituary   article   \n",
       "4  business/live/2024/jan/02/aldi-lidl-enjoy-reco...  liveblog   \n",
       "\n",
       "          sectionName publicationDate  \\\n",
       "0  Television & radio      2024-01-02   \n",
       "1         Environment      2024-01-02   \n",
       "2            Business      2024-01-02   \n",
       "3               Stage      2024-01-02   \n",
       "4            Business      2024-01-02   \n",
       "\n",
       "                                            webTitle  \\\n",
       "0  Before I Think You Should Leave, there was Det...   \n",
       "1  Climate crisis: 2023 was UK’s second-hottest y...   \n",
       "2  UK shop inflation sticks at 4.3% despite lower...   \n",
       "3                            Oliver Emanuel obituary   \n",
       "4  Tesla overtaken by China’s BYD as world’s top-...   \n",
       "\n",
       "                                              webUrl  \\\n",
       "0  https://www.theguardian.com/tv-and-radio/2024/...   \n",
       "1  https://www.theguardian.com/environment/2024/j...   \n",
       "2  https://www.theguardian.com/business/2024/jan/...   \n",
       "3  https://www.theguardian.com/stage/2024/jan/02/...   \n",
       "4  https://www.theguardian.com/business/live/2024...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Before I Think You Should Leave, there was Det...   \n",
       "1  Climate crisis: 2023 was UK’s second-hottest y...   \n",
       "2  UK shop inflation sticks at 4.3% despite lower...   \n",
       "3                            Oliver Emanuel obituary   \n",
       "4  Tesla overtaken by China’s BYD as world’s top-...   \n",
       "\n",
       "                                                body  \n",
       "0  <p>Pinning down why Tim Robinson is funny is v...  \n",
       "1  <p>The UK had its second-hottest year on recor...  \n",
       "2  <p>Shop prices continued to rise at 4.3% in De...  \n",
       "3  <p>Oliver Emanuel, who has died aged 43 from b...  \n",
       "4  <div id=\"block-6594260e8f083d1e9a9aea1a\" class...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if 'Unnamed: 0' in merged_df.columns:\n",
    "    merged_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert Date Columns to datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " After Converting Dates to datetime:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687 entries, 0 to 1686\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Open             1687 non-null   float64       \n",
      " 1   High             1687 non-null   float64       \n",
      " 2   Low              1687 non-null   float64       \n",
      " 3   Close            1687 non-null   float64       \n",
      " 4   Volume           1687 non-null   int64         \n",
      " 5   Dividends        1687 non-null   float64       \n",
      " 6   Stock Splits     1687 non-null   float64       \n",
      " 7   Date             1687 non-null   datetime64[ns]\n",
      " 8   id               1687 non-null   object        \n",
      " 9   type             1687 non-null   object        \n",
      " 10  sectionName      1687 non-null   object        \n",
      " 11  publicationDate  1687 non-null   datetime64[ns]\n",
      " 12  webTitle         1687 non-null   object        \n",
      " 13  webUrl           1687 non-null   object        \n",
      " 14  headline         1687 non-null   object        \n",
      " 15  body             1687 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(6), int64(1), object(7)\n",
      "memory usage: 211.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ensuring proper date format\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "merged_df['publicationDate'] = pd.to_datetime(merged_df['publicationDate'])\n",
    "# Show changes\n",
    "print(\"\\n After Converting Dates to datetime:\")\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Handle Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing Values Count (Before Handling):\n",
      "Open               0\n",
      "High               0\n",
      "Low                0\n",
      "Close              0\n",
      "Volume             0\n",
      "Dividends          0\n",
      "Stock Splits       0\n",
      "Date               0\n",
      "id                 0\n",
      "type               0\n",
      "sectionName        0\n",
      "publicationDate    0\n",
      "webTitle           0\n",
      "webUrl             0\n",
      "headline           0\n",
      "body               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show missing values BEFORE handling them\n",
    "print(\"\\n Missing Values Count (Before Handling):\")\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values were found in any column. This means the dataset does not require imputation, and missing value handling is not needed in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of Duplicate Rows (Before Removal): 5\n",
      "\n",
      " Number of Duplicate Rows (After Removal): 0\n",
      " Dataset Shape After Removing Duplicates: (1682, 16)\n"
     ]
    }
   ],
   "source": [
    "# Count duplicate rows BEFORE removal\n",
    "num_duplicates = merged_df.duplicated().sum()\n",
    "print(f\"\\n Number of Duplicate Rows (Before Removal): {num_duplicates}\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Show dataset shape AFTER removing duplicates\n",
    "print(f\"\\n Number of Duplicate Rows (After Removal): {merged_df.duplicated().sum()}\")\n",
    "print(f\" Dataset Shape After Removing Duplicates: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stock Price Summary (Before Winsorization):\n",
      "              Open         High          Low        Close\n",
      "count  1682.000000  1682.000000  1682.000000  1682.000000\n",
      "mean   5422.253513  5447.243239  5397.229180  5423.704060\n",
      "std     362.272588   363.299674   361.288070   362.140062\n",
      "min    4690.569824  4721.490234  4682.109863  4688.680176\n",
      "25%    5132.379883  5165.620117  5104.350098  5127.790039\n",
      "50%    5433.669922  5478.310059  5406.959961  5434.430176\n",
      "75%    5726.520020  5741.029785  5702.830078  5722.259766\n",
      "max    6089.029785  6099.970215  6079.979980  6090.270020\n",
      "\n",
      " Stock Price Summary (After Winsorization):\n",
      "              Open         High          Low        Close\n",
      "count  1682.000000  1682.000000  1682.000000  1682.000000\n",
      "mean   5422.457416  5447.322808  5397.333586  5423.993778\n",
      "std     361.458971   362.911485   360.676038   361.414349\n",
      "min    4739.129883  4744.229980  4714.819824  4739.209961\n",
      "25%    5132.379883  5165.620117  5104.350098  5127.790039\n",
      "50%    5433.669922  5478.310059  5406.959961  5434.430176\n",
      "75%    5726.520020  5741.029785  5702.830078  5722.259766\n",
      "max    6069.390137  6089.839844  6061.060059  6084.189941\n"
     ]
    }
   ],
   "source": [
    "# Show stock price summary BEFORE Winsorization\n",
    "print(\"\\n Stock Price Summary (Before Winsorization):\")\n",
    "print(merged_df[['Open', 'High', 'Low', 'Close']].describe())\n",
    "\n",
    "# Apply Winsorization (Capping extreme values)\n",
    "def winsorize_series(series, limits=[0.01, 0.01]):\n",
    "    return winsorize(series, limits=limits)\n",
    "\n",
    "for col in ['Open', 'High', 'Low', 'Close']:\n",
    "    merged_df[col] = winsorize_series(merged_df[col], limits=[0.01, 0.01])\n",
    "\n",
    "# Show stock price summary AFTER Winsorization\n",
    "print(\"\\n Stock Price Summary (After Winsorization):\")\n",
    "print(merged_df[['Open', 'High', 'Low', 'Close']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winsorization is used to cap extreme values in the stock price data, ensuring that outliers don’t skew the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scale Only Stock Market Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stock Price Summary (Before Scaling):\n",
      "              Open         High          Low        Close        Volume  \\\n",
      "count  1682.000000  1682.000000  1682.000000  1682.000000  1.682000e+03   \n",
      "mean   5422.457416  5447.322808  5397.333586  5423.993778  3.954992e+09   \n",
      "std     361.458971   362.911485   360.676038   361.414349  7.819356e+08   \n",
      "min    4739.129883  4744.229980  4714.819824  4739.209961  1.757720e+09   \n",
      "25%    5132.379883  5165.620117  5104.350098  5127.790039  3.530380e+09   \n",
      "50%    5433.669922  5478.310059  5406.959961  5434.430176  3.835170e+09   \n",
      "75%    5726.520020  5741.029785  5702.830078  5722.259766  4.140560e+09   \n",
      "max    6069.390137  6089.839844  6061.060059  6084.189941  8.223220e+09   \n",
      "\n",
      "       Dividends  Stock Splits  \n",
      "count     1682.0        1682.0  \n",
      "mean         0.0           0.0  \n",
      "std          0.0           0.0  \n",
      "min          0.0           0.0  \n",
      "25%          0.0           0.0  \n",
      "50%          0.0           0.0  \n",
      "75%          0.0           0.0  \n",
      "max          0.0           0.0  \n",
      "\n",
      " Stock Price Summary (After MinMax Scaling):\n",
      "              Open         High          Low        Close       Volume  \\\n",
      "count  1682.000000  1682.000000  1682.000000  1682.000000  1682.000000   \n",
      "mean      0.513680     0.522509     0.506978     0.509141     0.339846   \n",
      "std       0.271720     0.269700     0.267914     0.268714     0.120940   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.295619     0.313159     0.289347     0.288911     0.274172   \n",
      "50%       0.522108     0.545537     0.514128     0.516900     0.321313   \n",
      "75%       0.742253     0.740779     0.733903     0.730903     0.368547   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "       Dividends  Stock Splits  \n",
      "count     1682.0        1682.0  \n",
      "mean         0.0           0.0  \n",
      "std          0.0           0.0  \n",
      "min          0.0           0.0  \n",
      "25%          0.0           0.0  \n",
      "50%          0.0           0.0  \n",
      "75%          0.0           0.0  \n",
      "max          0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define stock market feature columns before using them\n",
    "stock_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
    "\n",
    "# Show numerical feature summary BEFORE scaling\n",
    "print(\"\\nStock Price Summary (Before Scaling):\")\n",
    "print(merged_df[stock_columns].describe())\n",
    "\n",
    "# Apply MinMax Scaling (Normalize values between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "merged_df[stock_columns] = scaler.fit_transform(merged_df[stock_columns])\n",
    "\n",
    "# Show numerical feature summary AFTER scaling\n",
    "print(\"\\n Stock Price Summary (After MinMax Scaling):\")\n",
    "print(merged_df[stock_columns].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before scaling:   \n",
    "Open, High, Low, Close values range from 4739 to 6084  \n",
    "Volume values are ranging from 1.75B to 8.22B\n",
    "- After scaling  \n",
    "  All values are between 0 and 1  \n",
    "  The relative differences between values are preserved  \n",
    "  Ensures equal contribution from all features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
