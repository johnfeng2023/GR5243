{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Transformation\n",
    "\n",
    "- One-hot encoding for categorical variables\n",
    "- Collapse low-frequency section names with 'Other'\n",
    "- Save the transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "merged_df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. One-hot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of article types before encoding:\n",
      "type\n",
      "article        1398\n",
      "liveblog        259\n",
      "interactive       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "type\n",
      "article        84.27\n",
      "liveblog       15.61\n",
      "interactive     0.12\n",
      "Name: count, dtype: float64 %\n",
      "\n",
      "Shape of encoded matrix: (1659, 2)\n",
      "\n",
      "Encoded columns (reference category excluded):\n",
      "['type_interactive', 'type_liveblog']\n",
      "\n",
      "Count of each encoded type:\n",
      "type_interactive: 2\n",
      "type_liveblog: 259\n"
     ]
    }
   ],
   "source": [
    "# Display original distribution\n",
    "print(\"Distribution of article types before encoding:\")\n",
    "print(merged_df['type'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print((merged_df['type'].value_counts() / len(merged_df) * 100).round(2), \"%\")\n",
    "\n",
    "# Perform one-hot encoding with dummy variable\n",
    "type_encoded = pd.get_dummies(merged_df['type'], prefix='type', drop_first=True)\n",
    "\n",
    "print(\"\\nShape of encoded matrix:\", type_encoded.shape)\n",
    "print(\"\\nEncoded columns (reference category excluded):\")\n",
    "print(type_encoded.columns.tolist())\n",
    "\n",
    "print(\"\\nCount of each encoded type:\")\n",
    "for col in type_encoded.columns:\n",
    "    print(f\"{col}: {type_encoded[col].sum()}\")\n",
    "\n",
    "# Add encoded columns to dataframe\n",
    "merged_df = pd.concat([merged_df, type_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collapse low-frequency section names with 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original number of sections: 38\n",
      "\n",
      "Sections to be collapsed (less than 5%):\n",
      "Music: 80 articles (4.8%)\n",
      "Sport: 64 articles (3.9%)\n",
      "Film: 61 articles (3.7%)\n",
      "Politics: 59 articles (3.6%)\n",
      "Television & radio: 53 articles (3.2%)\n",
      "Football: 51 articles (3.1%)\n",
      "Books: 49 articles (3.0%)\n",
      "Society: 48 articles (2.9%)\n",
      "Opinion: 45 articles (2.7%)\n",
      "Life and style: 44 articles (2.7%)\n",
      "Art and design: 38 articles (2.3%)\n",
      "Environment: 31 articles (1.9%)\n",
      "Education: 26 articles (1.6%)\n",
      "Games: 25 articles (1.5%)\n",
      "Stage: 25 articles (1.5%)\n",
      "Media: 23 articles (1.4%)\n",
      "Culture: 22 articles (1.3%)\n",
      "Technology: 17 articles (1.0%)\n",
      "Fashion: 17 articles (1.0%)\n",
      "Science: 16 articles (1.0%)\n",
      "Money: 13 articles (0.8%)\n",
      "Global development: 13 articles (0.8%)\n",
      "Wellness: 9 articles (0.5%)\n",
      "Food: 8 articles (0.5%)\n",
      "Stand Out By Design: 6 articles (0.4%)\n",
      "Travel: 5 articles (0.3%)\n",
      "Crosswords: 5 articles (0.3%)\n",
      "Law: 3 articles (0.2%)\n",
      "GNM press office: 3 articles (0.2%)\n",
      "News: 2 articles (0.1%)\n",
      "Visit The USA: The United States of Adventure: 1 articles (0.1%)\n",
      "The Filter: 1 articles (0.1%)\n",
      "From the Guardian: 1 articles (0.1%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate section frequencies and threshold\n",
    "section_counts = merged_df['sectionName'].value_counts()\n",
    "threshold_percent = 5\n",
    "threshold = len(merged_df) * threshold_percent / 100\n",
    "\n",
    "# Show sections to be collapsed\n",
    "print(\"\\nOriginal number of sections:\", len(section_counts))\n",
    "print(\"\\nSections to be collapsed (less than 5%):\")\n",
    "for section, count in section_counts[section_counts < threshold].items():\n",
    "    print(f\"{section}: {count} articles ({(count/len(merged_df)*100):.1f}%)\")\n",
    "\n",
    "# Replace low-frequency sections with 'Other'\n",
    "merged_df['sectionName'] = merged_df['sectionName'].apply(\n",
    "    lambda x: 'Other' if section_counts[x] < threshold else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final section distribution:\n",
      "sectionName\n",
      "Other             864\n",
      "Business          301\n",
      "UK news           175\n",
      "World news        125\n",
      "US news            98\n",
      "Australia news     96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final number of sections: 6\n",
      "\n",
      "Final dataset shape: (1659, 28)\n",
      "\n",
      "Columns in transformed dataset:\n",
      "- Unnamed: 0\n",
      "- X\n",
      "- Open\n",
      "- High\n",
      "- Low\n",
      "- Close\n",
      "- Volume\n",
      "- Dividends\n",
      "- Stock.Splits\n",
      "- Date\n",
      "- id\n",
      "- type\n",
      "- sectionName\n",
      "- publicationDate\n",
      "- webTitle\n",
      "- webUrl\n",
      "- headline\n",
      "- body\n",
      "- sentiment_score\n",
      "- sentiment_label\n",
      "- vader_score\n",
      "- vader_label\n",
      "- word_count\n",
      "- month\n",
      "- day\n",
      "- volatility\n",
      "- type_interactive\n",
      "- type_liveblog\n"
     ]
    }
   ],
   "source": [
    "# Show final distribution\n",
    "final_counts = merged_df['sectionName'].value_counts()\n",
    "print(\"\\nFinal section distribution:\")\n",
    "print(final_counts)\n",
    "print(\"\\nFinal number of sections:\", len(final_counts))\n",
    "\n",
    "# Display final dataset info\n",
    "print(\"\\nFinal dataset shape:\", merged_df.shape)\n",
    "print(\"\\nColumns in transformed dataset:\")\n",
    "for col in merged_df.columns:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed dataset saved to: final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the transformed dataset\n",
    "output_filename = 'processed_dataset.csv'\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "print(f\"\\nTransformed dataset saved to: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
